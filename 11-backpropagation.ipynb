{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmDF5APbKnZDLBY77QB7/4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lezione 11: La Correzione - Come la Rete Impara dagli Errori üß†üîß\n","\n","Nella lezione precedente abbiamo fatto un intero \"viaggio di andata\":\n","1.  Siamo partiti da un input (`x = 0.9`).\n","2.  Abbiamo attraversato la rete (Forward Propagation).\n","3.  Abbiamo ottenuto una previsione sbagliata (`y_predetto = 0.666`).\n","4.  Abbiamo calcolato un punteggio di errore (`errore = 0.1115`).\n","\n","Ora arriva la domanda da un milione di dollari: **come fa la rete a usare questo errore per migliorarsi?**\n","\n","La risposta √® un processo chiamato **Retropropagazione dell'Errore (Backpropagation)**. L'idea √® fare il viaggio al contrario: partiamo dall'errore finale e lo \"spingiamo\" all'indietro attraverso la rete per capire quali pesi hanno contribuito di pi√π allo sbaglio e come devono essere corretti."],"metadata":{"id":"eaiLQJzPm7nX"}},{"cell_type":"markdown","source":["Immagina che la nostra rete neurale sia un team di persone che lavora a una catena di montaggio per produrre un risultato. Alla fine della catena, un ispettore (la Funzione di Costo) dice: \"Il prodotto finale ha un difetto di 0.1115!\".\n","\n","Il capo (l'algoritmo di Backpropagation) deve capire chi ha sbagliato. Fa cos√¨:\n","1.  Va dall'**ultimo anello della catena** (il nostro neurone di output) e gli dice: \"Il tuo errore √® 0.1115. I tuoi fornitori erano il neurone nascosto 1 e il neurone nascosto 2. In base a quanto ti hanno passato e all'importanza che gli hai dato (i pesi `w3` e `w4`), assegna una parte della colpa a ciascuno di loro\".\n","2.  Il neurone di output calcola la \"quota di colpa\" per `N_h1` e `N_h2`.\n","3.  Il capo va da `N_h1` e gli dice: \"La tua parte di colpa √® X. Ora, in base al tuo fornitore (l'input) e all'importanza che gli hai dato (`w1`), calcola quanto √® colpa sua\".\n","4.  Questo processo continua all'indietro fino allo strato di input.\n","\n","Alla fine, ogni **peso** della rete ha ricevuto un \"punteggio di colpa\". Questo punteggio √® il **gradiente**! Ci dice due cose:\n","* **La direzione:** Aumentando o diminuendo questo peso, l'errore totale aumenter√† o diminuir√†?\n","* **L'intensit√†:** Di quanto √® \"colpevole\" questo peso? Un gradiente alto significa che quel peso ha un impatto enorme sull'errore finale."],"metadata":{"id":"iYaUn3iWnBiB"}},{"cell_type":"markdown","source":["Una volta che la backpropagation ha calcolato il gradiente (il \"punteggio di colpa\") per ogni singolo peso, entra in gioco un nostro vecchio amico: il **Gradient Descent**.\n","\n","Ricordi l'escursionista che doveva scendere nella valle dell'errore?\n","* La **Backpropagation** √® come la sua capacit√† di \"sentire la pendenza\" (il gradiente) sotto i piedi.\n","* Il **Gradient Descent** √® l'azione di \"fare un passo\" nella direzione opposta alla pendenza per scendere.\n","\n","La regola per aggiornare ogni peso √® semplicissima:\n","\n","**Nuovo Peso = Vecchio Peso - (Learning Rate * Gradiente di quel peso)**\n","\n","* **Learning Rate**: √à un numero piccolo (es. 0.1) che controlla la dimensione del passo. Evita che la rete corregga i pesi in modo troppo drastico.\n","\n","Facciamo un esempio numerico semplificato per vedere come viene aggiornato un solo peso."],"metadata":{"id":"nbdCJikcnMqf"}},{"cell_type":"code","source":["# --- RIPRENDIAMO I DATI DELLA LEZIONE 10 ---\n","# Vecchio peso w4 (dal neurone nascosto N_h2 all'output)\n","vecchio_w4 = 0.9\n","\n","# Definiamo un Learning Rate\n","learning_rate = 0.1\n","\n","# --- IL MIRACOLO DELLA BACKPROPAGATION ---\n","# Immaginiamo che, dopo complessi calcoli matematici (derivate parziali),\n","# l'algoritmo di backpropagation abbia calcolato il \"punteggio di colpa\"\n","# per il peso w4.\n","#\n","# Supponiamo che il risultato sia:\n","gradiente_di_w4 = 0.183\n","# Un valore positivo significa che AUMENTANDO w4, l'errore AUMENTA.\n","# Quindi, per ridurre l'errore, dobbiamo DIMINUIRE w4.\n","\n","# --- APPLICHIAMO LA REGOLA DEL GRADIENT DESCENT ---\n","nuovo_w4 = vecchio_w4 - (learning_rate * gradiente_di_w4)\n","# Calcolo: 0.9 - (0.1 * 0.183) = 0.9 - 0.0183 = 0.8817\n","\n","print(f\"Il vecchio peso w4 era: {vecchio_w4}\")\n","print(f\"Dopo un passo di correzione, il nuovo peso w4 √®: {nuovo_w4:.4f}\")\n","\n","# La rete ha leggermente ridotto il peso w4 perch√© ha capito\n","# che il suo valore era un po' troppo alto e contribuiva all'errore.\n","# Questo stesso identico processo viene fatto per TUTTI i pesi e i bias della rete!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kzAc8sunVz7","executionInfo":{"status":"ok","timestamp":1760041002558,"user_tz":-120,"elapsed":24,"user":{"displayName":"Francesco Belloni","userId":"11714019492918836159"}},"outputId":"2c519240-00b0-44c0-c2e2-71f1841c8638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Il vecchio peso w4 era: 0.9\n","Dopo un passo di correzione, il nuovo peso w4 √®: 0.8817\n"]}]},{"cell_type":"markdown","source":["Quello che abbiamo appena visto √® un singolo, minuscolo passo di apprendimento. Una rete neurale impara ripetendo questo ciclo decine di migliaia di volte:\n","\n","1.  **Prova (Forward Pass)**: Prendi un dato, passalo attraverso la rete e ottieni una previsione.\n","2.  **Misura (Calcolo del Costo)**: Confronta la previsione con la realt√† e calcola l'errore.\n","3.  **Correggi (Backward Pass / Backpropagation)**: Propaga l'errore all'indietro per calcolare il gradiente (la \"colpa\") di ogni peso.\n","4.  **Aggiorna (Gradient Descent)**: Usa i gradienti per aggiornare leggermente tutti i pesi.\n","5.  **Ripeti!**\n","\n","Ogni volta che la rete vede l'intero dataset di addestramento si dice che ha completato una **Epoca**. L'addestramento di una rete consiste nel farla girare per molte epoche, finch√© l'errore non diventa abbastanza piccolo.\n"],"metadata":{"id":"lQZKeTF7nohM"}},{"cell_type":"markdown","source":["### Un Laboratorio Pratico: Giochiamo con i Neuroni! üî¨\n","\n","Ora che abbiamo capito l'anatomia di una rete sulla carta, √® il momento di vederla in azione in un laboratorio virtuale, senza scrivere una sola riga di codice. Useremo uno strumento eccezionale chiamato **TensorFlow Playground**.\n","\n","**Apri questo link in una nuova scheda:** [**playground.tensorflow.org**](https://playground.tensorflow.org)\n","\n","\n","\n","Quello che vedi √® un simulatore di reti neurali. Prendiamoci un momento per capire l'interfaccia:\n","* **A Destra (I Dati):** C'√® il nostro problema. L'obiettivo della rete √® imparare a tracciare un confine che separi i punti arancioni da quelli blu.\n","* **Al Centro (La Rete):** Qui costruiamo la nostra rete. Vedi lo strato di **Input**, gli **Hidden Layers** (strati nascosti) e lo strato di **Output**. Puoi aggiungere o togliere strati e neuroni usando i pulsanti `+` e `-`.\n","* **A Sinistra (I Controlli):** Ci sono vari parametri come il \"Learning Rate\". Per ora, ignora quasi tutto.\n","\n","---\n","### La Tua Prima Missione üéØ\n","\n","Proviamo a risolvere il problema pi√π semplice. Segui questi passi:\n","\n","1.  **Scegli i Dati**: Assicurati che in alto a destra sia selezionato il primo dataset, quello a forma di **cerchio**.\n","2.  **Costruisci la Rete**: Al centro, crea una rete molto semplice: lascia i due input, crea **un solo strato nascosto** e mettici **3 neuroni**.\n","3.  **Avvia l'Addestramento**: Clicca sul pulsante \"Play\" ‚ñ∂Ô∏è in alto a sinistra.\n","\n","### Cosa Osservare üëÄ\n","\n","Mentre la rete impara, osserva tre cose:\n","* **Le linee tra i neuroni**: Rappresentano i **pesi**. Noterai che cambiano colore e spessore. Questo √® l'effetto dell'apprendimento! La rete sta \"sintonizzando\" l'importanza di ogni connessione.\n","* **L'output a destra**: Vedrai la rete che, iterazione dopo iterazione, colora lo sfondo e impara a tracciare un confine circolare sempre pi√π preciso per separare i punti.\n","* **Il grafico \"Test loss\"**: In alto a destra, vedrai un numero che scende rapidamente. Quello √® l'**errore** del nostro modello. Pi√π scende, pi√π la rete sta diventando brava. Questo √® un'anticipazione del **Gradient Descent** in azione.\n","\n","**Sperimenta!** Prova ad aggiungere o togliere neuroni, o a creare un secondo strato nascosto, e vedi come cambia la velocit√† e l'efficacia con cui la rete impara.\n","\n","Questo strumento ti d√† un'intuizione visiva potentissima di come √® fatta una rete e un'anteprima del suo processo di apprendimento, che analizzeremo nel dettaglio nelle prossime lezioni."],"metadata":{"id":"cugNqkbZvGGC"}},{"cell_type":"markdown","source":["### Dalle Linee Rette alle Decisioni Complesse: Il Superpotere degli Strati Nascosti\n","\n","Abbiamo visto che la rete √® fatta di strati. Ma perch√© ne serve pi√π di uno? Specialmente, perch√© sono cos√¨ importanti gli **strati nascosti**?\n","\n","La risposta sta in quello che ogni singolo neurone √® in grado di fare.\n","\n","**Un singolo neurone √® un separatore lineare.**\n","Se abbiamo solo due feature (come \"larghezza\" e \"altezza\" di un frutto), un neurone pu√≤ solo tracciare **una singola linea retta** per cercare di dividere i dati. √à utile, ma molto limitato. Non potrebbe mai separare dati disposti a cerchio, per esempio.\n","\n","**Pi√π neuroni nello stesso strato tracciano pi√π linee.**\n","Se nel nostro primo strato nascosto mettiamo **due neuroni**, questi impareranno a tracciare **due linee rette diverse**. Queste due linee dividono il nostro spazio in un massimo di 4 regioni.\n","\n","![Immagine di due rette che dividono un piano in quattro regioni]\n","\n","**Lo Strato Successivo impara a combinare le regioni.**\n","Qui avviene la vera magia. Lo strato successivo (un altro strato nascosto o quello di output) non vede i dati originali, ma riceve come input le \"decisioni\" dei neuroni precedenti. Il suo compito √® imparare una **regola per combinare queste regioni**.\n","\n","Potrebbe imparare qualcosa come: \"Se un dato si trova *sopra* la linea 1 **E** *a sinistra* della linea 2, allora appartiene alla classe 'Mela'\".\n","\n","Combinando abbastanza di questi semplici \"tagli\" lineari, una rete neurale pu√≤ creare confini decisionali di qualsiasi forma, anche molto complessi.\n","\n","**Perch√© questo √® fondamentale per le immagini?**\n","Un'immagine non √® altro che una griglia di pixel (le nostre feature).\n","* I **primi strati** della rete imparano a riconoscere cose semplicissime: un neurone potrebbe attivarsi se vede un **bordo verticale**, un altro se vede un **bordo orizzontale**, un altro ancora se riconosce una piccola **curva**. In pratica, ogni neurone traccia una \"linea\" nello spazio ad altissima dimensionalit√† dei pixel.\n","* Gli **strati successivi** combinano queste informazioni. Un neurone pi√π avanti potrebbe imparare ad attivarsi se riceve segnali dai neuroni che hanno visto \"una curva sopra a due linee verticali\", riconoscendo cos√¨ la forma di un **occhio**.\n","* Ancora pi√π avanti, un altro neurone potrebbe combinare le informazioni \"occhio\", \"naso\" e \"bocca\" per riconoscere un **viso**.\n","\n","Una rete neurale, quindi, costruisce la conoscenza in modo gerarchico: dai mattoni pi√π semplici (linee e curve) a concetti sempre pi√π astratti e complessi. Ecco perch√© aggiungere strati (rendere la rete \"profonda\" o *deep*) le permette di risolvere problemi cos√¨ difficili come la classificazione di immagini."],"metadata":{"id":"FPDFDs3Swipb"}},{"cell_type":"markdown","source":["**Nella prossima e ultima lezione**, metteremo insieme tutti questi pezzi, vedremo come si traducono in poche righe di codice reale e faremo il collegamento finale con lo strumento che userete per l'open day: **Teachable Machine**."],"metadata":{"id":"bU-gWU3-vNqq"}}]}